{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Qye42z6w1V"
      },
      "source": [
        "# CS 316 : Introduction to Deep Learning\n",
        "## Lab 04 : Linear Regression\n",
        "### Dr. Abdul Samad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhl9elIZ6yyg"
      },
      "source": [
        "# Instructions\n",
        "1. Please rename your notebook as *Lab_4_aa1234.ipynb* before the final submission. Notebooks which do not follow appropriate naming convention will not be graded. \n",
        "\n",
        "2. Filling out the feedback form on Canvas is mandatory. Failure to do so will result in you losing 10% of your grade for this lab.\n",
        "\n",
        "3. You have one week to submit this lab. Late submissions will be graded with a 30% penalty. No submission will be accepted after two weeks.\n",
        "\n",
        "4. Please submit your own work. If you have any questions, please feel free to reach out to the course instructor , RA or TA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFHfgmHp62B-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1XlnVk16noU"
      },
      "outputs": [],
      "source": [
        "# Importing the essentials\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqAoTxi37G4h"
      },
      "source": [
        "# Task Overview\n",
        "Create a linear regression model using the Boston Housing Dataset to find the set of equations to predict the price of a house. This lab has been divided into small subtasks to make it easier to follow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi5jJIrs7LqO"
      },
      "source": [
        "## [10 Points] Task 01 - Download Boston Housing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYGcbfgA7PsO"
      },
      "source": [
        "A suitable dataset is required in order to obtain a linear regression model with reasonable accuracy. There are numerous datasets available, and many of them can be found online. You can also download the dataset manually, but scripting its retrieval is more convenient and may save time.\n",
        "We'll use the urllib.request package to download the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txnPiWHs7TxI"
      },
      "source": [
        " The following is an example of using 'urllib.request' to download a cat photo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2i2By4_7NeF"
      },
      "outputs": [],
      "source": [
        "# Link from where to download.\n",
        "cat_pic = 'http://i3.ytimg.com/vi/J---aiyznGQ/mqdefault.jpg'\n",
        "# Path where you want to save.\n",
        "save_path = os.path.join(\"Good_Luck_Charms\", \"cat.jpg\")\n",
        "# If folder doesn't exist create it.\n",
        "if not os.path.isdir(\"Good_Luck_Charms\"):\n",
        "  os.mkdir(\"Good_Luck_Charms\")\n",
        "# If we have already save the file\n",
        "if os.path.exists(save_path):\n",
        "  print(\"File already exists\")\n",
        "else:\n",
        "  try:\n",
        "    urllib.request.urlretrieve(cat_pic, save_path)\n",
        "    print(f\"Cat picture added status: {os.path.exists(save_path)}\")\n",
        "  except:\n",
        "    raise Exception(f\"Something went wrong. Check your internet and download link.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SaGmbeC7fw4"
      },
      "source": [
        "**Your task is to download the Boston Housing Dataset by completing the function `get_boston_housing_dataset`.**\n",
        "\n",
        "**Link to Dataset**: [https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv](https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9DsrT6K7gX8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# TODO: Complete get_boston_housing_dataset\n",
        "def get_boston_housing_dataset(filename):\n",
        "    \"\"\"\n",
        "    Download the boston housing dataset. \n",
        "    If the file already exists, don't download the data again.\n",
        "    Add appropriate error handling as well.\n",
        "\n",
        "    Args:\n",
        "        filename (string): The path where you want to save the file.\n",
        "    Return:\n",
        "        bool : True, if the file already exists, or if you successfully downloaded the data.\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "if not os.path.isdir(\"datasets\"):\n",
        "  os.mkdir(\"datasets\")\n",
        "BostonHousingCSV = os.path.join(\"datasets\", \"BostonHousing.csv\")\n",
        "print(get_boston_housing_dataset(BostonHousingCSV))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J65Y2ubP9Wu7"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0acpv3D9dEJ"
      },
      "source": [
        "After downloading the csv file, let's observe the data and try to understand what it means. **The explanation for each column can be found at the end of the notebook in the section titled Explanations.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrWIRW7O9N0P"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "BostonHousingDataset = pd.read_csv(BostonHousingCSV)\n",
        "# View the top rows of the dataset\n",
        "BostonHousingDataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moND4Guj9hIB"
      },
      "source": [
        "There is a lot of data. Most of the variables are unlikely to have a significant impact on the price. To avoid dealing with irrelevant columns, let us first determine which variables have a strong correlation with median price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzl9ajyh9iiJ"
      },
      "outputs": [],
      "source": [
        "display.set_matplotlib_formats('svg')\n",
        "plt.figure(figsize=(8,8))\n",
        "correlation_matrix = BostonHousingDataset.corr().round(2)\n",
        "sns.heatmap(data=correlation_matrix, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v06g51MA9n5A"
      },
      "source": [
        "According to the heatmap, the two most important factors influencing price are **`lstat`** (Percentage of lower status of the population) and **`rm`** (Average number of rooms per dwelling). Consequently, we will be keep only these two columns. We can't add biases because we're only using matrices to find weights for each column. **As a result, we can add another column with a constant value of 1 that will serve as the bias.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oSuzh5y9kmn"
      },
      "outputs": [],
      "source": [
        "# Extract only the relevant columns. X: Input, Y: Output\n",
        "# iloc specifies the position of the column we want to select. :, part means all rows. ,-1 means last column\n",
        "output = BostonHousingDataset.iloc[:,-1] # we can also do BostonHousingDataset['medv']\n",
        "Y = np.array(output.values)\n",
        "# X = np.array(BostonHousingDataset[['lstat','rm','ptratio']].values)\n",
        "X = np.array(BostonHousingDataset[['lstat','rm']].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xAbEtXd9zLW"
      },
      "outputs": [],
      "source": [
        "ones = np.ones(shape=(len(X),1))\n",
        "X_with_bias = np.concatenate((X,ones),axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSO48LNL99g-"
      },
      "source": [
        "## [20 Points] Task 02 - Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsoKMqpB9_yu"
      },
      "source": [
        "To determine whether regression is effective, we can split our data into a training and test set and compare performance. Before splitting data, make sure to shuffle it because data is sometimes arranged in a specific order, such as all low-end houses first. If the data is not properly shuffled, it may fail to learn patterns. So, to avoid bias in your training data, shuffle it before splitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "687CG0A5-B3q"
      },
      "source": [
        "**Your task is to split the dataset into training and test dataset by completing the function `train_test_split(inputs,outputs,test_size,seed)`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH_3cHAI-D9O"
      },
      "source": [
        "**Important note on seed**: Reproducability is extremely important. Sometimes, you might find a good seed for a split. When dealing with random shuffling, you will get different results everytime you run. You can set a global seed by using `np.random.seed(42)` however that sets the global seed. It is useful over here to not change the global seed here, since if you want to reproduce the same result, you will have to run the entire code again. The solution to this problem is that you create a generator with a specific seed and use that for generation. [You can find more about setting seeds here](https://towardsdatascience.com/stop-using-numpy-random-seed-581a9972805f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHhzToqz96sI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_test_split(inputs,outputs,test_size,seed = 0):\n",
        "    \"\"\"\n",
        "    Splits the data into training and test sets.\n",
        "    Return 4 numpy arrays. X_train, X_test, Y_train, Y_test\n",
        "    where training data is test_size proportion of data provided.\n",
        "\n",
        "    Args:\n",
        "        inputs [np.array] : numpy array of input data\n",
        "        outputs [np.array]: numpy array of output labels\n",
        "        test_size [float]: proportion of data to be used as test data. e.g. 0.2 means 20% of data is used for test data.\n",
        "        seed [int]: A seed to create random number generator. (For reproducability) \n",
        "    \"\"\"\n",
        "   \n",
        "    rng = np.random.default_rng(seed)\n",
        "    assert(len(inputs) == len(outputs))\n",
        "    assert(test_size <= 1.0)\n",
        "    assert(test_size >= 0.0)\n",
        "    num_samples = len(inputs)\n",
        "    num_train = int(num_samples * (1.0 - test_size))\n",
        "    ...\n",
        "SEED = 0\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_with_bias,Y,0.2,seed = SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxcSne75Cqfl"
      },
      "source": [
        "## [10 Points] Task 03 - Analytic Solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uh0P0usCr_E"
      },
      "source": [
        "**In this Task, you are required to compute the analytic solution by completing the function `analytical_solution`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEPltchBCq_N",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#TODO: Complete analytical solution\n",
        "def analytical_solution(X,y):\n",
        "    \"\"\"\n",
        "    Returns the analytical solution to the dataset\n",
        "    Args:\n",
        "        X [np.array] : Inputs \n",
        "        y [np.array]: Outputs\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "\n",
        "w = analytical_solution(X_with_bias,Y)\n",
        "print(w)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oxiSRMWEy3P"
      },
      "source": [
        "## [20 Points] Task 04 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDT6bO-9FTx9"
      },
      "source": [
        "Mean Squared error is defined as\n",
        "\n",
        "$$\\text{MSE} = \\dfrac{1}{n}\\sum\\limits_{i=1}^{n}(y_i-\\hat{y}_i)^2$$\n",
        "\n",
        "where $y_i$ is your actual value and $\\hat{y}_i$ is the predicted value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4drJBje6FW-G"
      },
      "source": [
        "R2 score is also called the coefficient of determination. It basically is a statistical measure in a regression model that determines the proportion of variance in the dependent variable that can be explained by the independent variable. In simple words, how much of the output can actually be explained by the model or simply R2 just shows how well the data fit the regression model (the goodness of fit).\n",
        "\n",
        " $$R^2 = 1 - \\dfrac{RSS}{TSS}$$\n",
        "\n",
        "**RSS** is the sum of squares of residuals defined as\n",
        "$$\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "where $y_i$ is the actual value while $\\hat{y_i}$ is what you predict.\n",
        "\n",
        "**TSS** is defined as the Total sum of squares or simply the variance of our output variable. \n",
        "\n",
        "$$\\sum_{i=1}^{n} (y_i - \\bar{y})^2$$\n",
        "\n",
        "\n",
        "where $\\bar{y}$ is the mean value. \n",
        "\n",
        "Intuitively RSS/TSS is a ratio telling you how much a model sucks. So if RSS is 0, that means your model fits the data perfectly that is why 1 - RSS/TSS is **1. That's the best possible score you can get.** Furthemore, if your prediction is generally far from reality, your RSS would be pretty high, and that would make the score low. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWKeXrAIFaHJ"
      },
      "source": [
        "**In this task you are required to complete the functions `mean_squared_error` and `r2score`.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkYrcJMvE_II",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#TODO: Complete mean_squared_error\n",
        "def mean_squared_error(y_actual,y_prediction):\n",
        "    \"\"\"\n",
        "    Returns mean squared error using prediction and actual data\n",
        "    Args:\n",
        "        y_actual [np.array]     : Actual output vector \n",
        "        y_prediction [np.array] : Predicted output vector\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "#TODO: Complete r2score\n",
        "def r2score(y_test,y_pred):\n",
        "    \"\"\"\n",
        "    Returns the R2 score for the given test outputs and predictions\n",
        "    Args:\n",
        "        y_test [np.array]: Test outputs\n",
        "        y_pred [np.array]: Predictions\n",
        "    \"\"\"\n",
        "    ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjKZQ40RG25b"
      },
      "source": [
        "## [40 Points] Task 05 - Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9do-bfsGvKT"
      },
      "source": [
        "\n",
        "\n",
        "In this task, you will be implementing the Gradient Descent with and without the JAX libary. In both cases, you are required to train the model for 50 epochs and update the weights accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWnWSYw1GyYO"
      },
      "outputs": [],
      "source": [
        "# We would use X instead of X_with_bias since we have a b (bias) component)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,0.2,seed=SEED)\n",
        "# Initialize weights\n",
        "w = np.zeros(X_train.shape[0])\n",
        "b = 0\n",
        "lr = 0.005\n",
        "loss_graph = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AmDWfWMHhx2"
      },
      "source": [
        "### [20 Points] Part A : Without JAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGdvGo-xG78V",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#TODO: Write the main loop of Gradient Descent without using JAX\n",
        "...\n",
        "print(w,b)\n",
        "\n",
        "\n",
        "#TODO: Report the MSE and R2 score\n",
        "...\n",
        "r2s = r2score(Y_test,y_pred)\n",
        "mse = mean_squared_error(Y_test,y_pred)\n",
        "print(f\"R2 score after 50 epochs: {r2s}\")\n",
        "print(f\"Mean Square Error after 50 epoch: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE-l8szeN7up"
      },
      "source": [
        "### [20 Points] Part B: With JAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZbyl_meNc8O"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBCRRyE3OPlD"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,0.2,seed=SEED)\n",
        "w_jax = jnp.zeros(X_train.shape[0])\n",
        "b_jax = 0.\n",
        "lr = 0.003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp5HfAALORa1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#TODO: Write the main loop of Gradient Descent using JAX\n",
        "...\n",
        "print(w_jax,b_jax)\n",
        "\n",
        "#TODO: Report the MSE and R2 score\n",
        "...\n",
        "r2s_jax = r2score(Y_test,y_pred)\n",
        "mse_jax = mean_squared_error(Y_test,y_pred)\n",
        "print(f\"R2 score after 50 epochs: {r2s_jax}\")\n",
        "print(f\"Mean Square Error after 50 epoch: {mse_jax}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTRPdvcrPw91"
      },
      "source": [
        "\n",
        "<h2 id=\"Boston\"> Boston Housing Variables Meaning</h2>\n",
        "\n",
        "`crim` : Per capita crime rate by town\n",
        "\n",
        "`zn` : Proportion of residential land zoned for lots over 25,000 sq. ft\n",
        "\n",
        "`indus` : Proportion of non-retail business acres per town\n",
        "\n",
        "`chas` : Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "\n",
        "`nox` : Nitric oxide concentration (parts per 10 million)\n",
        "\n",
        "`rm` : Average number of rooms per dwelling\n",
        "\n",
        "`age` : Proportion of owner-occupied units built prior to 1940\n",
        "\n",
        "`dis` : Weighted distances to five Boston employment centers\n",
        "\n",
        "`rad` : Index of accessibility to radial highways\n",
        "\n",
        "`tax` : Full-value property tax rate per $10,000\n",
        "\n",
        "`ptratio` : Pupil-teacher ratio by town\n",
        "\n",
        "`b` : $1000(Bk — 0.63)^2$, where Bk is the proportion of [people of African American descent] by town\n",
        "\n",
        "`lstat` : Percentage of lower status of the population\n",
        "\n",
        "`medv` : Median value of owner-occupied homes in $1000s\n",
        "## Mean Squared Error\n",
        "\n",
        "$$\\text{MSE} = \\dfrac{1}{n}\\sum\\limits_{i=1}^{n}(y_i-\\hat{y}_i)^2$$\n",
        "\n",
        "It is simply on average how much your data deviates from the mean squared. (We square so the deviation doesn't get cancelled out).\n",
        "\n",
        "## R2/R-Squared Score\n",
        "\n",
        "R2 score is **how much** our input variables **determine** our output according to our model.\n",
        "\n",
        "$$R^2 = 1 - \\dfrac{RSS}{TSS}$$\n",
        "\n",
        "__RSS__ : __sum of squares of residuals__  \n",
        "$$\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "$y_i$ is the actual value while $\\hat{y_i}$ is what you predict.\n",
        "\n",
        "\n",
        "__TSS__ : __Total sum of squares__ or __variance of our output variable__. \n",
        "\n",
        "$$\\sum_{i=1}^{n} (y_i - \\bar{y})^2$$\n",
        "\n",
        "\n",
        "where $\\bar{y}$ is the mean value. \n",
        "\n",
        "\n",
        "When __RSS__ IS 0, that means your model has the perfect weights to predict the price according to the data you are testing on. When that is the case value is $1$. \n",
        "\n",
        "In practice, __RSS__ may not be 0, since there is noise and you might be eliminating other variables. If your R2 score is 0 or less, then your model is not a usable fit. Prediction that the price is always mean will give us R2 score of 0. The better the fit, the better the model\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Eti9pTHDO3w2"
      ],
      "name": "Lab_4_Task.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "otter": {
      "tests": {
        "Task01": {
          "name": "Task01",
          "points": 10,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task02": {
          "name": "Task02",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task03": {
          "name": "Task03",
          "points": 10,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task04": {
          "name": "Task04",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task05": {
          "name": "Task05",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Task06": {
          "name": "Task06",
          "points": 20,
          "suites": [
            {
              "cases": [],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "341ce806ad348c6396969bf6bfc3e3b2899dcbddac3f00a64251096e015967a2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}