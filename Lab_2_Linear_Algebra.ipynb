{"cells":[{"cell_type":"markdown","metadata":{"id":"J6U-9xmjQpcu"},"source":["# CS 316 : Introduction to Deep Learning\n","## Lab 02 : Linear Algebra\n","### Dr. Abdul Samad"]},{"cell_type":"markdown","metadata":{"id":"nimNXnNFQpc6"},"source":["# Overview"]},{"cell_type":"markdown","metadata":{"id":"QaGkzLdNQpc7"},"source":["We will cover the fundamentals of Linear Algebra using Numpy in this lab. We'll start by learning how to represent scalars, vectors, and matrices in Numpy, and then how to operate on them."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6i6xHP0jemSE","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1724829291008,"user_tz":-300,"elapsed":1361,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}},"outputId":"f156f4b1-954b-4377-dfbe-977238d8a53b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.26.4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["# Import numpy using the alias np\n","import numpy as np\n","np.__version__"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"Vzc95F3gemSH"},"source":["# Scalars\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6hkc6hJfQpdD"},"source":["In this course, we use mathematical notation in which scalar variables are denoted by lower-case letters (e.g., $x$, $y$, and $z$).\n","The space of all (continuous) *real-valued* scalars is denoted by $ \\mathbb{R} $.\n","For the sake of simplicity, we will avoid rigorous definitions of what exactly *space* is, but remember that the expression $x \\in \\mathbb{R}$ is a formal way of saying that $x$ is a real-valued scalar. The symbol $\\in$, which is pronounced \"in,\" denotes membership in a set.\n","Similarly, we could write $x, y \\in 0, 1$ to indicate that $x$ and $y$ are numbers with only $0$ or $1$ as values.\n","\n","**A tensor with only one element represents a scalar.** In the following snippet, we instantiate two scalars and use them to perform common arithmetic operations such as addition, multiplication, division, and exponentiation."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GeeEYziOemSJ","outputId":"948af0d0-2af6-4f2f-fe53-d05a25919715","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724829292496,"user_tz":-300,"elapsed":44,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5.0, 6.0, 1.5, 9.0)"]},"metadata":{},"execution_count":3}],"source":["x = np.array(3.0)\n","y = np.array(2.0)\n","\n","x + y, x * y, x / y, x**y"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"NU6dnSARemSL"},"source":["# Vectors\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qpscGAMwQpdH"},"source":["[**A vector is simply a list of scalar values.**]\n","These values are known as the vector's *elements* (or *entries* or *components*).\n","When our vectors represent examples from our dataset, their values have some real-world significance. For example, if we were training a model to predict the risk of a loan default, we might assign each applicant to a vector whose components correspond to their income, length of employment, number of previous defaults, and other factors. If we were researching the risk of heart attacks that hospital patients might face, we might represent each patient with a vector whose components capture their most recent vital signs, cholesterol levels, minutes of exercise per day, and so on. Vectors are typically denoted in mathematical notation as bold-faced, lower-cased letters (e.g., $\\mathbf{x}$, $\\mathbf{y}$, and $\\mathbf{z}$).\n","\n","We work with vectors using one-dimensional tensors. Tensors can have arbitrary lengths in general, subject to the memory constraints of your machine."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pi2tXUceemSM","outputId":"e318facb-df4f-47aa-ad11-aa8b67aa6b04","executionInfo":{"status":"ok","timestamp":1724829292496,"user_tz":-300,"elapsed":40,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3])"]},"metadata":{},"execution_count":4}],"source":["x = np.arange(4)\n","x"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"nnadfzwEemSM"},"source":["We can use a subscript to refer to any element of a vector. For example, we can refer to the $i^\\mathrm{th}$ element of $\\mathbf{x}$ as $x_i$.\n","Because the element $x_i$ is a scalar, we do not bold-face the font when referring to it. This book, like much of the literature, considers column vectors to be the default orientation of vectors. A vector $\\mathbf{x}$ can be written as\n","\n","$$\\mathbf{x} =\\begin{bmatrix}x_{1}  \\\\x_{2}  \\\\ \\vdots  \\\\x_{n}\\end{bmatrix},$$\n","\n","where $x_1, \\ldots, x_n$ are elements of the vector.\n","In code, we (**access any element by indexing into the tensor.**)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"KM5R7EVXemSN","outputId":"46c50eca-bbcb-4105-9883-c98ca7b0767a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724829292496,"user_tz":-300,"elapsed":35,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":5}],"source":["x[3]"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"3xTr8XH1emSO"},"source":["## Length, Dimensionality, and Shape\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DBoOTjyQQpdL"},"source":["To be clear. A vector is simply an array of numbers. And, like every array, every vector has a length.\n","If we want to express a vector in math notation as having $n$ real-valued scalars, we can write it as $\\mathbf{x}$ in $\\mathbb{R}^n$.\n","The length of a vector is commonly referred to as the vector's *dimension*. As with any other Python array, we can access the length of a tensor by using Python's built-in `len()` function.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFWcgYakemSP","outputId":"78b0f92c-5c14-4c89-ad66-c1859a6455d5","executionInfo":{"status":"ok","timestamp":1724829292497,"user_tz":-300,"elapsed":30,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":6}],"source":["len(x)\n"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"oesFG9NBemSQ"},"source":["When a tensor represents a vector (with exactly one axis), its length can be accessed via the `.shape` attribute.\n","The shape is a tuple that lists the length (dimensionality) of the tensor along each axis.\n","(**The shape has only one element for tensors with only one axis.**)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AL0hr-yremSR","outputId":"bc30b590-f23b-4c5a-ef36-c2bb00a61962","executionInfo":{"status":"ok","timestamp":1724829292497,"user_tz":-300,"elapsed":27,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4,)"]},"metadata":{},"execution_count":7}],"source":["x.shape"]},{"cell_type":"markdown","metadata":{"id":"QksH99qCQpdO"},"source":["It should be noted that the word \"dimension\" is frequently overused in these contexts, which leads to confusion.\n","To be clear, we refer to the dimensionality of a *vector* or a *axis* as its length, i.e. the number of elements of a vector or an axis.\n","However, we refer to a tensor's dimensionality as the number of axes that it has.\n","In this sense, the dimensionality of a tensor axis is the length of that axis."]},{"cell_type":"markdown","metadata":{"id":"tMokNjOoQpdP"},"source":["## Vector - Vector Multiplication"]},{"cell_type":"markdown","metadata":{"id":"0mOXlgchQpdP"},"source":["### Hadamard Product"]},{"cell_type":"markdown","metadata":{"id":"JQfA_jMvQpdP"},"source":["The Hadamard product is a binary operation that takes two vectors of the same dimensions and generates another vector of the same dimensions as the operands, with each element ij being the product of the original two vectors' elements i, j."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DenzL-sQpdQ","executionInfo":{"status":"ok","timestamp":1724829292497,"user_tz":-300,"elapsed":24,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}},"outputId":"82e99d63-e4ed-42f6-af38-78f211b9e619"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4,)\n","(4,)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.])"]},"metadata":{},"execution_count":8}],"source":["x = np.arange(4)\n","y = np.ones(4)\n","print(x.shape)\n","print(y.shape)\n","np.multiply(x,y)"]},{"cell_type":"markdown","metadata":{"id":"dswdvjcPQpdQ"},"source":["### Dot Product"]},{"cell_type":"markdown","metadata":{"id":"LxTUScv2QpdR"},"source":["We've only done elementwise operations, sums, and averages so far. And if this were all we had to offer, linear algebra might not even merit its own section. However, the dot product is one of the most fundamental operations.\n","\n","Given two vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$, their *dot product* $\\mathbf{x}^\\top \\mathbf{y}$ or $\\langle \\mathbf{x}, \\mathbf{y} \\rangle$ is a sum of the products of the elements at the same index: $\\mathbf{x}^\\top \\mathbf{y} = \\sum_{i=1}^{d} x_i y_i$"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"66VbjgqLQpdR","executionInfo":{"status":"ok","timestamp":1724829292497,"user_tz":-300,"elapsed":20,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}},"outputId":"b2627fb3-4522-437b-fadd-3c00c2b434cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4,)\n","(4,)\n","6.0\n","6.0\n","6.0\n"]}],"source":["x = np.arange(4)\n","y = np.ones(4)\n","print(x.shape)\n","print(y.shape)\n","print(np.dot(x.T,y))\n","print(x.T @ y)\n","print (np.sum(x * y))"]},{"cell_type":"markdown","metadata":{"id":"ma_mn328QpdS"},"source":["### Outer product"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xbr52-HQpdS","executionInfo":{"status":"ok","timestamp":1724829292498,"user_tz":-300,"elapsed":16,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}},"outputId":"96aa13f4-f4be-4d1b-b8e1-e18d2fb72cf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 1)\n","(3, 1)\n","[[0. 0. 0.]\n"," [1. 1. 1.]\n"," [2. 2. 2.]\n"," [3. 3. 3.]]\n"]}],"source":["u = np.arange(4).reshape((4,1))\n","v = np.ones(3).reshape((3,1))\n","print(u.shape)\n","print(v.shape)\n","print(u @ v.T)"]},{"cell_type":"markdown","metadata":{"id":"wjGEESt0QpdT"},"source":["# Matrices"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"kM1H1lVGemSR"},"source":["Just as vectors generalize scalars from order zero to order one,\n","matrices generalize vectors from order one to order two.\n","Matrices, which we will typically denote with bold-faced, capital letters\n","(e.g., $\\mathbf{X}$, $\\mathbf{Y}$, and $\\mathbf{Z}$),\n","are represented in code as tensors with two axes.\n","\n","In math notation, we use $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$\n","to express that the matrix $\\mathbf{A}$ consists of $m$ rows and $n$ columns of real-valued scalars.\n","Visually, we can illustrate any matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ as a table,\n","where each element $a_{ij}$ belongs to the $i^{\\mathrm{th}}$ row and $j^{\\mathrm{th}}$ column:\n","\n","$$\\mathbf{A}=\\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\ a_{21} & a_{22} & \\cdots & a_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & \\cdots & a_{mn} \\\\ \\end{bmatrix}.$$\n","\n","\n","For any $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, the shape of $\\mathbf{A}$\n","is ($m$, $n$) or $m \\times n$.\n","Specifically, when a matrix has the same number of rows and columns,\n","its shape becomes a square; thus, it is called a *square matrix*.\n","\n","We can [**create an $m \\times n$ matrix**]\n","by specifying a shape with two components $m$ and $n$\n","when calling any of our favorite functions for instantiating a tensor.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KjiSu1jIemSS","outputId":"0ff9e08f-dd4f-49a1-cb23-7b27b5c1f481","executionInfo":{"status":"ok","timestamp":1724829292498,"user_tz":-300,"elapsed":12,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  1,  2,  3],\n","       [ 4,  5,  6,  7],\n","       [ 8,  9, 10, 11],\n","       [12, 13, 14, 15],\n","       [16, 17, 18, 19]])"]},"metadata":{},"execution_count":11}],"source":["A = np.arange(20).reshape(5, 4)\n","A"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"eNLUTIqsQpdU","outputId":"7eca3ad0-6972-46df-fc9f-e4e7f0bb8025","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724829312178,"user_tz":-300,"elapsed":382,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["5\n"]}],"source":["# len(A)\n","print(A.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsHY6q9rQpdV","outputId":"1d0112a9-a463-4a64-8a72-d768b0704d0d"},"outputs":[{"data":{"text/plain":["20"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["A.reshape(-1).shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJpQPTe-QpdV","outputId":"13a8c563-2366-489e-f120-0b0041a91636"},"outputs":[{"data":{"text/plain":["array([[1., 0., 0., 0.],\n","       [0., 1., 0., 0.],\n","       [0., 0., 1., 0.],\n","       [0., 0., 0., 1.]])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["I = np.eye(4)\n","I"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qkz_0HufQpdW","outputId":"1a613e90-ea02-4b99-a5dc-da572f3c82e2"},"outputs":[{"data":{"text/plain":["array([[ 1,  0,  0,  0],\n","       [ 0,  4,  0,  0],\n","       [ 0,  0,  8,  0],\n","       [ 0,  0,  0, 16]])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["D = np.diag([1,4,8,16])\n","D"]},{"cell_type":"markdown","metadata":{"id":"vcGe2vi8QpdX"},"source":["## Matrix-Vector Products"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"8KgcH4f7emST"},"source":["\n","\n","Now that we know how to calculate dot products,\n","we can begin to understand *matrix-vector products*.\n","Recall the matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$\n","and the vector $\\mathbf{x} \\in \\mathbb{R}^n$\n","defined .\n","Let us start off by visualizing the matrix $\\mathbf{A}$ in terms of its row vectors\n","\n","$$\\mathbf{A}=\n","\\begin{bmatrix}\n","\\mathbf{a}^\\top_{1} \\\\\n","\\mathbf{a}^\\top_{2} \\\\\n","\\vdots \\\\\n","\\mathbf{a}^\\top_m \\\\\n","\\end{bmatrix},$$\n","\n","where each $\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^n$\n","is a row vector representing the $i^\\mathrm{th}$ row of the matrix $\\mathbf{A}$.\n","\n","[**The matrix-vector product $\\mathbf{A}\\mathbf{x}$\n","is simply a column vector of length $m$,\n","whose $i^\\mathrm{th}$ element is the dot product $\\mathbf{a}^\\top_i \\mathbf{x}$:**]\n","\n","$$\n","\\mathbf{A}\\mathbf{x}\n","= \\begin{bmatrix}\n","\\mathbf{a}^\\top_{1} \\\\\n","\\mathbf{a}^\\top_{2} \\\\\n","\\vdots \\\\\n","\\mathbf{a}^\\top_m \\\\\n","\\end{bmatrix}\\mathbf{x}\n","= \\begin{bmatrix}\n"," \\mathbf{a}^\\top_{1} \\mathbf{x}  \\\\\n"," \\mathbf{a}^\\top_{2} \\mathbf{x} \\\\\n","\\vdots\\\\\n"," \\mathbf{a}^\\top_{m} \\mathbf{x}\\\\\n","\\end{bmatrix}.\n","$$\n","\n","We can think of multiplication by a matrix $\\mathbf{A}\\in \\mathbb{R}^{m \\times n}$\n","as a transformation that projects vectors\n","from $\\mathbb{R}^{n}$ to $\\mathbb{R}^{m}$.\n","These transformations turn out to be remarkably useful.\n","For example, we can represent rotations\n","as multiplications by a square matrix.\n","As we will see in subsequent chapters,\n","we can also use matrix-vector products\n","to describe the most intensive calculations\n","required when computing each layer in a neural network\n","given the values of the previous layer.\n","\n","Expressing matrix-vector products in code with tensors,\n","we use the same `dot` function as for dot products.\n","When we call `np.dot(A, x)` with a matrix `A` and a vector `x`,\n","the matrix-vector product is performed.\n","Note that the column dimension of `A` (its length along axis 1)\n","must be the same as the dimension of `x` (its length).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgOrYlyEemSU","outputId":"b934c962-f902-48de-9a64-ec93f4f7d1e7"},"outputs":[{"data":{"text/plain":["((5, 4), (4,), array([ 14,  38,  62,  86, 110]))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["A = np.arange(20).reshape(5, 4)\n","x = np.arange(4)\n","A.shape, x.shape, np.dot(A, x)"]},{"cell_type":"markdown","metadata":{"id":"z-E_7VGYQpdZ"},"source":["## Matrix-Matrix Multiplication"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"fUrgx2rGemSU"},"source":["\n","\n","\n","Say that we have two matrices $\\mathbf{A} \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{B} \\in \\mathbb{R}^{k \\times m}$:\n","\n","$$\\mathbf{A}=\\begin{bmatrix}\n"," a_{11} & a_{12} & \\cdots & a_{1k} \\\\\n"," a_{21} & a_{22} & \\cdots & a_{2k} \\\\\n","\\vdots & \\vdots & \\ddots & \\vdots \\\\\n"," a_{n1} & a_{n2} & \\cdots & a_{nk} \\\\\n","\\end{bmatrix},\\quad\n","\\mathbf{B}=\\begin{bmatrix}\n"," b_{11} & b_{12} & \\cdots & b_{1m} \\\\\n"," b_{21} & b_{22} & \\cdots & b_{2m} \\\\\n","\\vdots & \\vdots & \\ddots & \\vdots \\\\\n"," b_{k1} & b_{k2} & \\cdots & b_{km} \\\\\n","\\end{bmatrix}.$$\n","\n","\n","Denote by $\\mathbf{a}^\\top_{i} \\in \\mathbb{R}^k$\n","the row vector representing the $i^\\mathrm{th}$ row of the matrix $\\mathbf{A}$,\n","and let $\\mathbf{b}_{j} \\in \\mathbb{R}^k$\n","be the column vector from the $j^\\mathrm{th}$ column of the matrix $\\mathbf{B}$.\n","To produce the matrix product $\\mathbf{C} = \\mathbf{A}\\mathbf{B}$, it is easiest to think of $\\mathbf{A}$ in terms of its row vectors and $\\mathbf{B}$ in terms of its column vectors:\n","\n","$$\\mathbf{A}=\n","\\begin{bmatrix}\n","\\mathbf{a}^\\top_{1} \\\\\n","\\mathbf{a}^\\top_{2} \\\\\n","\\vdots \\\\\n","\\mathbf{a}^\\top_n \\\\\n","\\end{bmatrix},\n","\\quad \\mathbf{B}=\\begin{bmatrix}\n"," \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n","\\end{bmatrix}.\n","$$\n","\n","\n","Then the matrix product $\\mathbf{C} \\in \\mathbb{R}^{n \\times m}$ is produced as we simply compute each element $c_{ij}$ as the dot product $\\mathbf{a}^\\top_i \\mathbf{b}_j$:\n","\n","$$\\mathbf{C} = \\mathbf{AB} = \\begin{bmatrix}\n","\\mathbf{a}^\\top_{1} \\\\\n","\\mathbf{a}^\\top_{2} \\\\\n","\\vdots \\\\\n","\\mathbf{a}^\\top_n \\\\\n","\\end{bmatrix}\n","\\begin{bmatrix}\n"," \\mathbf{b}_{1} & \\mathbf{b}_{2} & \\cdots & \\mathbf{b}_{m} \\\\\n","\\end{bmatrix}\n","= \\begin{bmatrix}\n","\\mathbf{a}^\\top_{1} \\mathbf{b}_1 & \\mathbf{a}^\\top_{1}\\mathbf{b}_2& \\cdots & \\mathbf{a}^\\top_{1} \\mathbf{b}_m \\\\\n"," \\mathbf{a}^\\top_{2}\\mathbf{b}_1 & \\mathbf{a}^\\top_{2} \\mathbf{b}_2 & \\cdots & \\mathbf{a}^\\top_{2} \\mathbf{b}_m \\\\\n"," \\vdots & \\vdots & \\ddots &\\vdots\\\\\n","\\mathbf{a}^\\top_{n} \\mathbf{b}_1 & \\mathbf{a}^\\top_{n}\\mathbf{b}_2& \\cdots& \\mathbf{a}^\\top_{n} \\mathbf{b}_m\n","\\end{bmatrix}.\n","$$\n","\n","[**We can think of the matrix-matrix multiplication $\\mathbf{AB}$ as simply performing $m$ matrix-vector products and stitching the results together to form an $n \\times m$ matrix.**]\n","In the following snippet, we perform matrix multiplication on `A` and `B`.\n","Here,Â `A` is a matrix with 5 rows and 4 columns,\n","and `B` is a matrix with 4 rows and 3 columns.\n","After multiplication, we obtain a matrix with 5 rows and 3 columns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJGwirmpemSV"},"outputs":[],"source":["A = np.arange(20).reshape(5, 4)\n","B = np.ones(shape=(4, 4))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_zYPtL2Qpdn","outputId":"88d91cf3-0a9b-49b9-9120-4c25eb4a8016"},"outputs":[{"data":{"text/plain":["array([[ 6.,  6.,  6.],\n","       [22., 22., 22.],\n","       [38., 38., 38.],\n","       [54., 54., 54.],\n","       [70., 70., 70.]])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["np.dot(A, B)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spBzDpZWQpdo","outputId":"330f36eb-360b-49ec-ccc2-67373e0d668a"},"outputs":[{"data":{"text/plain":["array([[ 6.,  6.,  6.],\n","       [22., 22., 22.],\n","       [38., 38., 38.],\n","       [54., 54., 54.],\n","       [70., 70., 70.]])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["np.matmul(A,B)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GA5zmu12Qpdo","outputId":"d2546c7d-aa9f-423a-8ac8-1ca2de80a19f"},"outputs":[{"data":{"text/plain":["array([[ 6.,  6.,  6.],\n","       [22., 22., 22.],\n","       [38., 38., 38.],\n","       [54., 54., 54.],\n","       [70., 70., 70.]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["A @ B"]},{"cell_type":"markdown","metadata":{"id":"baMj_F8KQpdp"},"source":["# Linear Algebra Module"]},{"cell_type":"markdown","metadata":{"id":"JmIIXX60Qpdp"},"source":["The NumPy library contains a submodule `linalg` which provides provide efficient low level implementations of standard linear algebra algorithms. In this lab, we will only cover functions such as finding an inverse or rank of a matrix. However, more details can be found on the following link. <a src=\"https://numpy.org/doc/stable/reference/routines.linalg.html\">Documentation</a>"]},{"cell_type":"markdown","metadata":{"id":"P5k50srNQpdq"},"source":["## Inverse"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"h1yb7oKwQpdq","outputId":"72d25922-e569-4f5a-8d29-92f86fdcb6f1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724829834672,"user_tz":-300,"elapsed":374,"user":{"displayName":"Mohd Anas","userId":"11618215162887796579"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["det(A) = -2.0000000000000004\n","A = [[1. 2.]\n"," [3. 4.]]\n","A^-1 = [[-2.   1. ]\n"," [ 1.5 -0.5]]\n","A^-1 A = [[1. 0.]\n"," [0. 1.]]\n"]}],"source":["A = np.array([[1., 2.], [3., 4.]])\n","invA = np.linalg.inv(np.matrix(A))\n","result = invA @ A\n","# print(np.result, 'result')\n","print(f'det(A) = {np.linalg.det(A)}')\n","print(f'A = {A}')\n","print(f'A^-1 = {invA}')\n","print(f'A^-1 A = {np.round(result,2)}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"341ce806ad348c6396969bf6bfc3e3b2899dcbddac3f00a64251096e015967a2"}}},"nbformat":4,"nbformat_minor":0}